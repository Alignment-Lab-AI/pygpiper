import os
import json
import multiprocessing
import requests
import time
import yaml
from datetime import datetime

BATCH_SIZE = 20
MAX_RETRIES = 99999999
RETRY_DELAY = 30
TOTAL_GENERATIONS = 100000 # Set your desired total number of generations here

# Directories setup
if not os.path.exists('aug/output'):
    os.makedirs('aug/output')
if not os.path.exists('aug/malformed'):
    os.makedirs('aug/malformed')
if not os.path.exists('aug/rejected'):
    os.makedirs('aug/rejected')
if not os.path.exists('templates'):
    os.makedirs('templates')

class OpenAI_API:
    def __init__(self):
        print("Initializing...")
        self.session = None
        self.total_generations_processed = 0

    def load_templates(self):
        print("Loading templates...")
        templates = []
        for filename in sorted(os.listdir('templates')):
            if filename.endswith('.txt'):
                with open(os.path.join('templates', filename), 'r') as f:
                    templates.append(f.read().strip())
        return templates

    def construct_prompt(self, yaml_content, template):
        """
        Constructs a prompt by appending the template to the YAML content.

        :param yaml_content: A string containing the content of a YAML file.
        :param template: A string template to be appended under the YAML content.
        :return: A string with the YAML content followed by the template.
        """
        return json.dumps(yaml_content) + "\n" + template

    def process_yaml_files(self):
        templates = self.load_templates()
        yaml_folder = 'aug/final'
        template_idx = 0

        output_folder = 'aug/output'  # Updated output folder path

        for filename in sorted(os.listdir(yaml_folder)):
            if filename.endswith('.yml') or filename.endswith('.yaml'):
                with open(os.path.join(yaml_folder, filename), 'r') as f:
                    yaml_content = yaml.load(f, Loader=yaml.FullLoader)
                    while self.total_generations_processed < TOTAL_GENERATIONS:
                        tasks = []
                        for _ in range(BATCH_SIZE):
                            if self.total_generations_processed >= TOTAL_GENERATIONS:
                                break

                            prompt = self.construct_prompt(yaml_content, templates[template_idx])
                            template_idx = (template_idx + 1) % len(templates)

                            task = multiprocessing.Process(target=self.send_prompt, args=(prompt, output_folder, filename, yaml_content, templates[template_idx]))
                            tasks.append(task)

                        for task in tasks:
                            task.start()

                        for task in tasks:
                            task.join()


        print("Processing complete.")    

    def send_prompt(self, prompt, output_folder, filename, yaml_content, template):
        print(f"Sending prompt...")
        base_url = os.environ.get('OPENAI_API_BASE')
        url = f"{base_url}/chat/completions"
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f"Bearer {os.environ.get('OPENAI_API_KEY')}"
        }
        data = {
            "transforms": [],
            "model": "mistralai/Mixtral-8x7B-Instruct-v0.1",
            "temperature": 0.1,
            "messages": [{"role": "user", "content": prompt}]
        }

        try:
            response = requests.post(url, headers=headers, json=data)
            if response.status_code == 200:
                result = response.json()
                print(f"Received successful response.")
                print(result)
                response_data = yaml_content
                response_data.update({
                    'template': template,
                    'augmentation': result["choices"][0]["message"]["content"]
                })
                timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
                output_file = f"{filename}_{timestamp}.jsonl"
                with open(os.path.join(output_folder, output_file), "w") as outfile:
                    json.dump(response_data, outfile, indent=4)
                os.remove(os.path.join('aug/final', filename))
                self.total_generations_processed += 1
            elif response.status_code == 429:
                print(f"Rate limit hit. Retrying after {RETRY_DELAY} seconds...")
                time.sleep(RETRY_DELAY)
            else:
                error_content = response.text
                print(f"Failed to get response, status code: {response.status_code}, error: {error_content}")
                if response.status_code == 403:
                    self.handle_rejection(prompt, error_content)
        except Exception as e:
            print(f"Exception encountered: {e}")

    def handle_rejection(self, prompt, error):
        print(f"Handling rejection...")
        rejected_file_path = os.path.join('aug/rejected', f"{prompt}.jsonl")
        with open(rejected_file_path, "w") as f:
            f.write(json.dumps({'error': error, 'prompt': prompt}) + '\n')

if __name__ == "__main__":
    api = OpenAI_API()
    api.process_yaml_files()

